{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WELCOME TO WEEK 6\n",
    "\n",
    "The Epic Finale Week\n",
    "\n",
    "And\n",
    "\n",
    "# WELCOME TO THE **M**ODEL **C**ONTEXT **P**ROTOCOL!\n",
    "\n",
    "And welcome back to OpenAI Agents SDK ❤️❤️❤️\n",
    "\n",
    "### UPDATE:\n",
    "\n",
    "I've made improvements to the code for this week. MCP is rapidly evolving, and I'm trying to take advantage of the latest. You'll find that the code has advanced from the videos. For example, in the final project, we have 4 traders with a live feed of their inner thoughts.. All the improvements will be explained fully in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">To my Windows PC people - an important announcement</h2>\n",
    "            <span style=\"color:#ff7800;\">I have unpleasant news. There's a problem running MCP Servers on Windows PCs; Mac and Linux is fine. This is a known issue as of May 4th, 2025. I asked o3 with Deep Research to try to find workarounds; it <a href=\"https://chatgpt.com/share/6817bbc3-3d0c-8012-9b51-631842470628\">confirmed the issue</a> and confirmed the workaround.<br/><br/>\n",
    "            The workaround is a bit of a bore. It is to take advantage of \"WSL\", the Microsoft approach for running Linux on your PC. You'll need to carry out more setup instructions! But it's quick, and several students have confirmed that this works perfectly for them, then the Week 6 MCP labs work. Plus, WSL is actually a great way to build software on your Windows PC.<br/>\n",
    "            The WSL Setup instructions are in the Setup folder, <a href=\"../setup/SETUP-WSL.md\">in the file called SETUP-WSL.md here</a>. I do hope this only holds you up briefly - you should be back up and running quickly. Oh the joys of working with bleeding-edge technology!<br/><br/>\n",
    "            With many thanks to students Markus, Abhi, Hui-Ling, and several others, for helping me work on it and confirming the fix.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use MCP in OpenAI Agents SDK\n",
    "\n",
    "1. Create a Client\n",
    "\n",
    "2. Have it spawn a server\n",
    "\n",
    "3. Collect the tools that the server can use\n",
    "\n",
    "Let's try the Fetch mcp-server that we looked at last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PATH\"] = os.path.expanduser(\"~/.local/bin\") + \":\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/reema14a/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which uvx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch: Fetches a URL from the internet and optionally extracts its contents as markdown.  Although originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace this with your actual uvx path\n",
    "uvx_path = os.path.expanduser(\"~/.local/bin/uvx\")\n",
    "\n",
    "fetch_params = {\"command\": uvx_path, \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "async with MCPServerStdio(params=fetch_params, client_session_timeout_seconds=30) as server:\n",
    "    fetch_tools = await server.list_tools()\n",
    "\n",
    "for tool in fetch_tools:\n",
    "    print(f\"{tool.name}: {tool.description.replace('\\n', ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra installation step - if you don't have \"node\" on your computer\n",
    "\n",
    "The next MCP tool uses node (the Javascript Server), and it needs you to have the command 'npx' installed on your computer.\n",
    "\n",
    "You may already have this, but if not, here are super clear instructions on exactly what to do, courtesy of our friend.  \n",
    "And thank you to student avid_learner for pointing this out.\n",
    "\n",
    "https://chatgpt.com/share/68103af2-e2dc-8012-b259-bc135a23273b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now repeat for 3 more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Manually add node's path to the environment used by subprocesses\n",
    "os.environ[\"PATH\"] += \":/usr/local/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/node\n"
     ]
    }
   ],
   "source": [
    "!which node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puppeteer_navigate: Navigate to a URL\n",
      "puppeteer_screenshot: Take a screenshot of the current page or a specific element\n",
      "puppeteer_click: Click an element on the page\n",
      "puppeteer_fill: Fill out an input field\n",
      "puppeteer_select: Select an element on the page with Select tag\n",
      "puppeteer_hover: Hover an element on the page\n",
      "puppeteer_evaluate: Execute JavaScript in the browser console\n"
     ]
    }
   ],
   "source": [
    "\n",
    "puppeteer_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-puppeteer\"]}\n",
    "\n",
    "async with MCPServerStdio(params=puppeteer_params, client_session_timeout_seconds=30) as server:\n",
    "    puppeteer_tools = await server.list_tools()\n",
    "\n",
    "for tool in puppeteer_tools:\n",
    "    print(f\"{tool.name}: {tool.description.replace('\\n', ' ')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='puppeteer_navigate', description='Navigate to a URL', inputSchema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to navigate to'}, 'launchOptions': {'type': 'object', 'description': \"PuppeteerJS LaunchOptions. Default null. If changed and not null, browser restarts. Example: { headless: true, args: ['--no-sandbox'] }\"}, 'allowDangerous': {'type': 'boolean', 'description': 'Allow dangerous LaunchOptions that reduce security. When false, dangerous args like --no-sandbox will throw errors. Default false.'}}, 'required': ['url']}, annotations=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puppeteer_tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_file: Read the complete contents of a file from the file system. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Only works within allowed directories.\n",
      "read_multiple_files: Read the contents of multiple files simultaneously. This is more efficient than reading files one by one when you need to analyze or compare multiple files. Each file's content is returned with its path as a reference. Failed reads for individual files won't stop the entire operation. Only works within allowed directories.\n",
      "write_file: Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories.\n",
      "edit_file: Make line-based edits to a text file. Each edit replaces exact line sequences with new content. Returns a git-style diff showing the changes made. Only works within allowed directories.\n",
      "create_directory: Create a new directory or ensure a directory exists. Can create multiple nested directories in one operation. If the directory already exists, this operation will succeed silently. Perfect for setting up directory structures for projects or ensuring required paths exist. Only works within allowed directories.\n",
      "list_directory: Get a detailed listing of all files and directories in a specified path. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is essential for understanding directory structure and finding specific files within a directory. Only works within allowed directories.\n",
      "directory_tree: Get a recursive tree view of files and directories as a JSON structure. Each entry includes 'name', 'type' (file/directory), and 'children' for directories. Files have no children array, while directories always have a children array (which may be empty). The output is formatted with 2-space indentation for readability. Only works within allowed directories.\n",
      "move_file: Move or rename files and directories. Can move files between directories and rename them in a single operation. If the destination exists, the operation will fail. Works across different directories and can be used for simple renaming within the same directory. Both source and destination must be within allowed directories.\n",
      "search_files: Recursively search for files and directories matching a pattern. Searches through all subdirectories from the starting path. The search is case-insensitive and matches partial names. Returns full paths to all matching items. Great for finding files when you don't know their exact location. Only searches within allowed directories.\n",
      "get_file_info: Retrieve detailed metadata about a file or directory. Returns comprehensive information including size, creation time, last modified time, permissions, and type. This tool is perfect for understanding file characteristics without reading the actual content. Only works within allowed directories.\n",
      "list_allowed_directories: Returns the list of directories that this server is allowed to access. Use this to understand which directories are available before trying to access files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=30) as server:\n",
    "    file_tools = await server.list_tools()\n",
    "\n",
    "for tool in file_tools:\n",
    "    print(f\"{tool.name}: {tool.description.replace('\\n', ' ')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "browser_close: Close the page\n",
      "browser_resize: Resize the browser window\n",
      "browser_console_messages: Returns all console messages\n",
      "browser_handle_dialog: Handle a dialog\n",
      "browser_file_upload: Upload one or multiple files\n",
      "browser_install: Install the browser specified in the config. Call this if you get an error about the browser not being installed.\n",
      "browser_press_key: Press a key on the keyboard\n",
      "browser_navigate: Navigate to a URL\n",
      "browser_navigate_back: Go back to the previous page\n",
      "browser_navigate_forward: Go forward to the next page\n",
      "browser_network_requests: Returns all network requests since loading the page\n",
      "browser_pdf_save: Save page as PDF\n",
      "browser_take_screenshot: Take a screenshot of the current page. You can't perform actions based on the screenshot, use browser_snapshot for actions.\n",
      "browser_snapshot: Capture accessibility snapshot of the current page, this is better than screenshot\n",
      "browser_click: Perform click on a web page\n",
      "browser_drag: Perform drag and drop between two elements\n",
      "browser_hover: Hover over element on page\n",
      "browser_type: Type text into editable element\n",
      "browser_select_option: Select an option in a dropdown\n",
      "browser_tab_list: List browser tabs\n",
      "browser_tab_new: Open a new tab\n",
      "browser_tab_select: Select a tab by index\n",
      "browser_tab_close: Close a tab\n",
      "browser_generate_playwright_test: Generate a Playwright test for given scenario\n",
      "browser_wait_for: Wait for text to appear or disappear or a specified time to pass\n"
     ]
    }
   ],
   "source": [
    "\n",
    "playwright_params = {\"command\": \"npx\", \"args\": [\"@playwright/mcp@latest\"]}\n",
    "\n",
    "async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=30) as server:\n",
    "    playwright_tools = await server.list_tools()\n",
    "\n",
    "for tool in playwright_tools:\n",
    "    print(f\"{tool.name.replace('\\n', ' ')}: {tool.description.replace('\\n', ' ')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now.. bring on the Agent with Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key exists and begins AI\n"
     ]
    }
   ],
   "source": [
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     13\u001b[39m agent = Agent(\n\u001b[32m     14\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33minvestigator\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     15\u001b[39m     instructions=instructions, \n\u001b[32m     16\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     mcp_servers=[mcp_server_files, mcp_server_browser]\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33minvestigate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(agent, \u001b[33m\"\u001b[39m\u001b[33mFind a great recipe for Banoffee Pie, then summarize it in markdown to banoffee.md\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/agents/run.py:218\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    213\u001b[39m logger.debug(\n\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m )\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m    221\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    222\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    223\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    224\u001b[39m             context_wrapper,\n\u001b[32m    225\u001b[39m         ),\n\u001b[32m    226\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    227\u001b[39m             agent=current_agent,\n\u001b[32m    228\u001b[39m             all_tools=all_tools,\n\u001b[32m    229\u001b[39m             original_input=original_input,\n\u001b[32m    230\u001b[39m             generated_items=generated_items,\n\u001b[32m    231\u001b[39m             hooks=hooks,\n\u001b[32m    232\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    233\u001b[39m             run_config=run_config,\n\u001b[32m    234\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    235\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    236\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/agents/run.py:760\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    758\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    761\u001b[39m     agent,\n\u001b[32m    762\u001b[39m     system_prompt,\n\u001b[32m    763\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    764\u001b[39m     output_schema,\n\u001b[32m    765\u001b[39m     all_tools,\n\u001b[32m    766\u001b[39m     handoffs,\n\u001b[32m    767\u001b[39m     context_wrapper,\n\u001b[32m    768\u001b[39m     run_config,\n\u001b[32m    769\u001b[39m     tool_use_tracker,\n\u001b[32m    770\u001b[39m     previous_response_id,\n\u001b[32m    771\u001b[39m )\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    774\u001b[39m     agent=agent,\n\u001b[32m    775\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    784\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    785\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/agents/run.py:919\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    916\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    917\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    920\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    921\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    922\u001b[39m     model_settings=model_settings,\n\u001b[32m    923\u001b[39m     tools=all_tools,\n\u001b[32m    924\u001b[39m     output_schema=output_schema,\n\u001b[32m    925\u001b[39m     handoffs=handoffs,\n\u001b[32m    926\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    927\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    928\u001b[39m     ),\n\u001b[32m    929\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    930\u001b[39m )\n\u001b[32m    932\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:76\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     77\u001b[39m             system_instructions,\n\u001b[32m     78\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     79\u001b[39m             model_settings,\n\u001b[32m     80\u001b[39m             tools,\n\u001b[32m     81\u001b[39m             output_schema,\n\u001b[32m     82\u001b[39m             handoffs,\n\u001b[32m     83\u001b[39m             previous_response_id,\n\u001b[32m     84\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     85\u001b[39m         )\n\u001b[32m     87\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     88\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:242\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m     logger.debug(\n\u001b[32m    233\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    234\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    239\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    243\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    244\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    245\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    246\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    247\u001b[39m     include=converted_tools.includes,\n\u001b[32m    248\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    249\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    250\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    251\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    252\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    253\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    254\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    255\u001b[39m     stream=stream,\n\u001b[32m    256\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    257\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    258\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    259\u001b[39m     text=response_format,\n\u001b[32m    260\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    261\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    262\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    263\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:1559\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, input, model, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1529\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1530\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1531\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1557\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1558\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1561\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1562\u001b[39m             {\n\u001b[32m   1563\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1564\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1565\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1566\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1567\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1568\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1569\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1570\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1571\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1572\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1573\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1574\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1575\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1577\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1578\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1580\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1581\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1582\u001b[39m             },\n\u001b[32m   1583\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1584\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1585\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1586\u001b[39m         ),\n\u001b[32m   1587\u001b[39m         options=make_request_options(\n\u001b[32m   1588\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1589\u001b[39m         ),\n\u001b[32m   1590\u001b[39m         cast_to=Response,\n\u001b[32m   1591\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1592\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1593\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1484\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1482\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1485\u001b[39m         request,\n\u001b[32m   1486\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1487\u001b[39m         **kwargs,\n\u001b[32m   1488\u001b[39m     )\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1490\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1674\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1672\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1674\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1675\u001b[39m     request,\n\u001b[32m   1676\u001b[39m     auth=auth,\n\u001b[32m   1677\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1678\u001b[39m     history=[],\n\u001b[32m   1679\u001b[39m )\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1702\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1699\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1703\u001b[39m         request,\n\u001b[32m   1704\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1705\u001b[39m         history=history,\n\u001b[32m   1706\u001b[39m     )\n\u001b[32m   1707\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1708\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1739\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1736\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1776\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1772\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1773\u001b[39m     )\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1779\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:377\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    364\u001b[39m req = httpcore.Request(\n\u001b[32m    365\u001b[39m     method=request.method,\n\u001b[32m    366\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m     extensions=request.extensions,\n\u001b[32m    375\u001b[39m )\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    382\u001b[39m     status_code=resp.status,\n\u001b[32m    383\u001b[39m     headers=resp.headers,\n\u001b[32m    384\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    385\u001b[39m     extensions=resp.extensions,\n\u001b[32m    386\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/anyio/streams/tls.py:219\u001b[39m, in \u001b[36mTLSStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m = \u001b[32m65536\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_sslobject_method(\u001b[38;5;28mself\u001b[39m._ssl_object.read, max_bytes)\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/anyio/streams/tls.py:162\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write_bio.pending:\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m._read_bio.write_eof()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Udemy-AgenticAIEnggCourse/agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-x86_64-none/lib/python3.12/asyncio/locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "instructions = \"\"\"\n",
    "You browse the internet to accomplish your instructions.\n",
    "You are highly capable at browsing the internet independently to accomplish your task, \n",
    "including accepting all cookies and clicking 'not now' as\n",
    "appropriate to get to the content you need. If one website isn't fruitful, try another. \n",
    "Be persistent until you have solved your assignment,\n",
    "trying different options and sites as needed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async with MCPServerStdio(params=files_params, cache_tools_list=True) as mcp_server_files:\n",
    "    async with MCPServerStdio(params=playwright_params, cache_tools_list=True, client_session_timeout_seconds=30) as mcp_server_browser:\n",
    "        agent = Agent(\n",
    "            name=\"investigator\", \n",
    "            instructions=instructions, \n",
    "            model=\"gpt-4o-mini\",\n",
    "            mcp_servers=[mcp_server_files, mcp_server_browser]\n",
    "            )\n",
    "        with trace(\"investigate\"):\n",
    "            result = await Runner.run(agent, \"Find a great recipe for Banoffee Pie, then summarize it in markdown to banoffee.md\")\n",
    "            print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### Now take a look at some MCP marketplaces\n",
    "\n",
    "https://mcp.so\n",
    "\n",
    "https://glama.ai/mcp\n",
    "\n",
    "https://smithery.ai/\n",
    "\n",
    "https://huggingface.co/blog/LLMhacker/top-11-essential-mcp-libraries\n",
    "\n",
    "HuggingFace great community article:\n",
    "https://huggingface.co/blog/Kseniase/mcp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
